{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYeBDmdWMkgh",
        "outputId": "0f6f98e1-b6ee-4637-fe27-0bb8c0ba64f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version is 2.19.0\n",
            "GPU is available\n",
            "Physical GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: environment check and installations (if any)\n",
        "# This cell is checking for GPU availability and printing device info.\n",
        "import tensorflow as tf\n",
        "import os\n",
        "print(\"TensorFlow version is\", tf.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT available\")\n",
        "try:\n",
        "    print(\"Physical GPUs:\", tf.config.list_physical_devices('GPU'))\n",
        "except Exception as e:\n",
        "    print(\"GPU check is raising:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: imports and global settings\n",
        "# This cell is importing required libraries and setting global hyperparameters.\n",
        "import zipfile\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# This cell is fixing random seeds for reproducibility.\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# This cell is setting core hyperparameters which you can change.\n",
        "maxVocabSize = 30000\n",
        "maxSeqLen = 256\n",
        "embeddingDim = 128\n",
        "batchSize = 128\n",
        "numEpochs = 12\n",
        "validationSplit = 0.1\n"
      ],
      "metadata": {
        "id": "b9bJIsPZO9VY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: data loader and preprocessing classes\n",
        "# This cell is defining classes for loading, preprocessing, and generating pairs.\n",
        "\n",
        "class ZipDatasetLoader:\n",
        "    \"\"\"This class is handling unzipping and reading csv files.\"\"\"\n",
        "    def __init__(self, zipPath=\"archive.zip\", extractTo=\"/content/archive\"):\n",
        "        self.zipPath = zipPath\n",
        "        self.extractTo = extractTo\n",
        "        os.makedirs(self.extractTo, exist_ok=True)\n",
        "\n",
        "    def extractZip(self):\n",
        "        \"\"\"This function is extracting archive.zip into the working directory.\"\"\"\n",
        "        with zipfile.ZipFile(self.zipPath, 'r') as z:\n",
        "            z.extractall(self.extractTo)\n",
        "        print(\"Archive is extracted to\", self.extractTo)\n",
        "\n",
        "    def loadCsvFiles(self):\n",
        "        \"\"\"This function is reading all csv files from the extracted archive and returning a dataframe list.\"\"\"\n",
        "        csvPaths = glob.glob(os.path.join(self.extractTo, \"**\", \"*.csv\"), recursive=True)\n",
        "        dfs = []\n",
        "        for p in csvPaths:\n",
        "            df = pd.read_csv(p)\n",
        "            # This block is ensuring columns 'clause_text' or similar are normalized.\n",
        "            # This code is trying common name patterns.\n",
        "            cols = [c.lower() for c in df.columns]\n",
        "            if 'clause_text' in cols:\n",
        "                textCol = df.columns[cols.index('clause_text')]\n",
        "            elif 'text' in cols:\n",
        "                textCol = df.columns[cols.index('text')]\n",
        "            elif 'clause' in cols:\n",
        "                textCol = df.columns[cols.index('clause')]\n",
        "            else:\n",
        "                # fallback to first column\n",
        "                textCol = df.columns[0]\n",
        "            # This code is trying to find a label/type column.\n",
        "            if 'clause_type' in cols:\n",
        "                typeCol = df.columns[cols.index('clause_type')]\n",
        "            elif 'type' in cols:\n",
        "                typeCol = df.columns[cols.index('type')]\n",
        "            elif 'label' in cols:\n",
        "                typeCol = df.columns[cols.index('label')]\n",
        "            else:\n",
        "                # fallback to second column if exists\n",
        "                typeCol = df.columns[1] if df.shape[1] > 1 else None\n",
        "\n",
        "            # This code is constructing standardized dataframe\n",
        "            tmp = pd.DataFrame()\n",
        "            tmp['clauseText'] = df[textCol].astype(str).fillna(\"\")\n",
        "            tmp['clauseType'] = df[typeCol].astype(str).fillna(\"\") if typeCol is not None else \"\"\n",
        "            tmp['sourceFile'] = os.path.basename(p)\n",
        "            dfs.append(tmp)\n",
        "        if not dfs:\n",
        "            raise FileNotFoundError(\"No CSV files are found in the archive extract path.\")\n",
        "        allDf = pd.concat(dfs, ignore_index=True)\n",
        "        print(\"Total clauses are\", len(allDf))\n",
        "        return allDf\n",
        "\n",
        "class PairGenerator:\n",
        "    \"\"\"This class is generating similarity pairs from clause dataframe.\"\"\"\n",
        "    def __init__(self, clauseDf):\n",
        "        self.df = clauseDf.copy()\n",
        "        # This line is cleaning clauseType to ensure string values.\n",
        "        self.df['clauseType'] = self.df['clauseType'].astype(str).fillna(\"\")\n",
        "        self.typeGroups = self.df.groupby('clauseType').indices\n",
        "\n",
        "    def simpleTextClean(self, text):\n",
        "        \"\"\"This function is doing basic text cleaning.\"\"\"\n",
        "        text = text.lower()\n",
        "        # This line is removing repeated whitespace and non-printable characters.\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        return text\n",
        "\n",
        "    def generatePairs(self, maxPairsPerType=5000, negativeToPositiveRatio=1.0):\n",
        "        \"\"\"This function is creating pairs labelled 1 for similar and 0 for not similar.\n",
        "           Similarity is being approximated by same clauseType; different types are considered not similar.\n",
        "        \"\"\"\n",
        "        # This code is normalizing texts.\n",
        "        self.df['cleanText'] = self.df['clauseText'].apply(self.simpleTextClean)\n",
        "        types = list(self.typeGroups.keys())\n",
        "        posPairs = []\n",
        "        # This loop is creating positive pairs from same clause type.\n",
        "        for t, idxs in self.typeGroups.items():\n",
        "            idxList = list(idxs)\n",
        "            if len(idxList) < 2:\n",
        "                continue\n",
        "            # This code is sampling and creating pairs.\n",
        "            random.shuffle(idxList)\n",
        "            # generate up to n positive pairs per type\n",
        "            count = 0\n",
        "            for i in range(len(idxList)):\n",
        "                for j in range(i+1, len(idxList)):\n",
        "                    posPairs.append((self.df.loc[idxList[i],'cleanText'], self.df.loc[idxList[j],'cleanText'], 1))\n",
        "                    count += 1\n",
        "                    if count >= maxPairsPerType:\n",
        "                        break\n",
        "                if count >= maxPairsPerType:\n",
        "                    break\n",
        "\n",
        "        # This code is creating negative pairs by pairing clauses from different types.\n",
        "        negPairs = []\n",
        "        numNegNeeded = int(len(posPairs) * negativeToPositiveRatio)\n",
        "        allIdxs = list(self.df.index)\n",
        "        while len(negPairs) < numNegNeeded:\n",
        "            a, b = random.sample(allIdxs, 2)\n",
        "            if self.df.loc[a, 'clauseType'] != self.df.loc[b, 'clauseType']:\n",
        "                negPairs.append((self.df.loc[a,'cleanText'], self.df.loc[b,'cleanText'], 0))\n",
        "\n",
        "        pairs = posPairs + negPairs\n",
        "        random.shuffle(pairs)\n",
        "        print(\"Pairs are generated: positives =\", len(posPairs), \"negatives =\", len(negPairs))\n",
        "        # This code is splitting into inputs and labels.\n",
        "        lefts = [p[0] for p in pairs]\n",
        "        rights = [p[1] for p in pairs]\n",
        "        labels = [p[2] for p in pairs]\n",
        "        return lefts, rights, np.array(labels)\n"
      ],
      "metadata": {
        "id": "WSjdDmXvO_QT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: tokenization and dataset preparation\n",
        "# This cell is extracting the zip, loading data, generating pairs, tokenizing and preparing train/test splits.\n",
        "\n",
        "# This block is extracting archive.zip and reading all CSVs.\n",
        "loader = ZipDatasetLoader(zipPath=\"/content/archive.zip\", extractTo=\"/content/archive\")\n",
        "loader.extractZip()\n",
        "dfClauses = loader.loadCsvFiles()\n",
        "\n",
        "# This block is generating pairs.\n",
        "pairGen = PairGenerator(dfClauses)\n",
        "leftTexts, rightTexts, labels = pairGen.generatePairs(maxPairsPerType=300, negativeToPositiveRatio=1.0)\n",
        "\n",
        "# This block is tokenizing texts using Keras Tokenizer trained from scratch.\n",
        "allTexts = leftTexts + rightTexts\n",
        "tokenizer = Tokenizer(num_words=maxVocabSize, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(allTexts)\n",
        "print(\"Tokenizer is fitted. Vocab size (approx) =\", min(maxVocabSize, len(tokenizer.word_index)+1))\n",
        "\n",
        "# This block is converting texts to sequences and padding them.\n",
        "leftSeq = tokenizer.texts_to_sequences(leftTexts)\n",
        "rightSeq = tokenizer.texts_to_sequences(rightTexts)\n",
        "leftPad = pad_sequences(leftSeq, maxlen=maxSeqLen, padding='post', truncating='post')\n",
        "rightPad = pad_sequences(rightSeq, maxlen=maxSeqLen, padding='post', truncating='post')\n",
        "\n",
        "# This block is creating train/test split.\n",
        "X = np.stack([leftPad, rightPad], axis=1)  # shape = (N, 2, seqLen)\n",
        "y = labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=SEED, stratify=y)\n",
        "# This block is creating validation split from train for the fit call using validationSplit param in Keras.\n",
        "print(\"Data shapes are:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo2RWTFJPFzU",
        "outputId": "5285e238-2e57-48c1-9b90-6f4dde628f68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive is extracted to /content/archive\n",
            "Total clauses are 150881\n",
            "Pairs are generated: positives = 118305 negatives = 118305\n",
            "Tokenizer is fitted. Vocab size (approx) = 30000\n",
            "Data shapes are: (201118, 2, 256) (35492, 2, 256) (201118,) (35492,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: model builder (Siamese BiLSTM and Attention Encoder)\n",
        "# This cell is defining a modular ModelBuilder class that is creating two models.\n",
        "\n",
        "class ModelBuilder:\n",
        "    \"\"\"This class is building multiple neural architectures for clause similarity.\"\"\"\n",
        "    def __init__(self, vocabSize, embeddingDim=128, maxLen=256):\n",
        "        self.vocabSize = vocabSize\n",
        "        self.embeddingDim = embeddingDim\n",
        "        self.maxLen = maxLen\n",
        "\n",
        "    def buildEmbeddingLayer(self):\n",
        "        \"\"\"This function is returning a Keras Embedding layer for shared usage.\"\"\"\n",
        "        return layers.Embedding(input_dim=self.vocabSize, output_dim=self.embeddingDim,\n",
        "                                input_length=self.maxLen, mask_zero=False, name=\"sharedEmbedding\")\n",
        "\n",
        "    def buildSiameseBiLstm(self, lstmUnits=64, dropout=0.2):\n",
        "        \"\"\"This function is building a siamese BiLSTM encoder with distance-based head.\"\"\"\n",
        "        embed = self.buildEmbeddingLayer()\n",
        "        # This block is defining the encoder model used for both inputs.\n",
        "        seqInput = Input(shape=(self.maxLen,), dtype='int32', name=\"seqInput\")\n",
        "        x = embed(seqInput)\n",
        "        x = layers.Bidirectional(layers.LSTM(lstmUnits, return_sequences=False), name=\"bilstm\")(x)\n",
        "        x = layers.Dropout(dropout)(x)\n",
        "        encoded = layers.Dense(lstmUnits, activation='relu', name=\"encodedDense\")(x)\n",
        "        encoder = Model(seqInput, encoded, name=\"siameseEncoder\")\n",
        "\n",
        "        # This block is creating two inputs and computing absolute difference and multiplication.\n",
        "        leftInput = Input(shape=(self.maxLen,), name=\"leftInput\")\n",
        "        rightInput = Input(shape=(self.maxLen,), name=\"rightInput\")\n",
        "        leftVec = encoder(leftInput)\n",
        "        rightVec = encoder(rightInput)\n",
        "        # This line is combining vectors using abs diff and multiply (Siamese style).\n",
        "        absDiff = layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([leftVec, rightVec])\n",
        "        mult = layers.Multiply()([leftVec, rightVec])\n",
        "        merged = layers.Concatenate()([absDiff, mult])\n",
        "        merged = layers.Dense(128, activation='relu')(merged)\n",
        "        merged = layers.Dropout(0.2)(merged)\n",
        "        out = layers.Dense(1, activation='sigmoid')(merged)\n",
        "        model = Model([leftInput, rightInput], out, name=\"siameseBiLstm\")\n",
        "        model.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def buildAttentionEncoder(self, lstmUnits=64, dropout=0.2):\n",
        "        \"\"\"This function is building a dual-encoder using BiLSTM + self-attention over tokens.\"\"\"\n",
        "        embed = self.buildEmbeddingLayer()\n",
        "        def encoderBlock(namePrefix):\n",
        "            seqInput = Input(shape=(self.maxLen,), dtype='int32', name=f\"{namePrefix}_input\")\n",
        "            x = embed(seqInput)\n",
        "            x = layers.Bidirectional(layers.LSTM(lstmUnits, return_sequences=True), name=f\"{namePrefix}_bilstm\")(x)\n",
        "            # This block is computing a simple token-level attention (learnable).\n",
        "            attnScores = layers.Dense(1, activation='tanh')(x)   # (batch, seqLen, 1)\n",
        "            attnWeights = layers.Softmax(axis=1)(attnScores)     # normalize across seqLen\n",
        "            context = layers.Multiply()([x, attnWeights])        # weighted tokens\n",
        "            contextVec = layers.Lambda(lambda z: tf.reduce_sum(z, axis=1))(context)  # sum pooling\n",
        "            contextVec = layers.Dense(lstmUnits, activation='relu')(contextVec)\n",
        "            return seqInput, contextVec\n",
        "\n",
        "        leftInput, leftVec = encoderBlock(\"left\")\n",
        "        rightInput, rightVec = encoderBlock(\"right\")\n",
        "\n",
        "        # This line is composing vector interactions.\n",
        "        combined = layers.Concatenate()([leftVec, rightVec, layers.Lambda(lambda t: tf.abs(t[0]-t[1]))([leftVec, rightVec])])\n",
        "        combined = layers.Dense(256, activation='relu')(combined)\n",
        "        combined = layers.Dropout(dropout)(combined)\n",
        "        combined = layers.Dense(64, activation='relu')(combined)\n",
        "        out = layers.Dense(1, activation='sigmoid')(combined)\n",
        "\n",
        "        model = Model([leftInput, rightInput], out, name=\"attentionEncoder\")\n",
        "        model.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        return model\n"
      ],
      "metadata": {
        "id": "mQXZTWfSPfuG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: helper training & evaluation functions\n",
        "# This cell is defining train and evaluate utilities (OOP friendly).\n",
        "\n",
        "def fitModel(model, X_train, y_train, modelName=\"model\", epochs=numEpochs, batch_size=batchSize):\n",
        "    \"\"\"This function is training given model and returning training history and best file path.\"\"\"\n",
        "    leftTrain = X_train[:,0]\n",
        "    rightTrain = X_train[:,1]\n",
        "    bestPath = f\"/content/{modelName}_best.h5\"\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n",
        "        ModelCheckpoint(bestPath, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "    ]\n",
        "    history = model.fit([leftTrain, rightTrain], y_train,\n",
        "                        validation_split=validationSplit,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        callbacks=callbacks,\n",
        "                        verbose=2)\n",
        "    return history, bestPath\n",
        "\n",
        "def evaluateModel(model, X_eval, y_eval):\n",
        "    \"\"\"This function is evaluating model on test set and returning common metrics.\"\"\"\n",
        "    leftEval = X_eval[:,0]\n",
        "    rightEval = X_eval[:,1]\n",
        "    probs = model.predict([leftEval, rightEval], batch_size=256, verbose=0).ravel()\n",
        "    preds = (probs >= 0.5).astype(int)\n",
        "    acc = accuracy_score(y_eval, preds)\n",
        "    prec, recall, f1, _ = precision_recall_fscore_support(y_eval, preds, average='binary', zero_division=0)\n",
        "    # This block is handling case when only single class is present (roc_auc would fail)\n",
        "    try:\n",
        "        roc = roc_auc_score(y_eval, probs)\n",
        "    except Exception as e:\n",
        "        roc = float(\"nan\")\n",
        "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1, \"roc_auc\": roc}, probs, preds\n",
        "\n",
        "def showQualitativeExamples(leftTexts, rightTexts, y_true, y_pred, probs, tokenizerObj, maxLen=256, numExamples=10):\n",
        "    \"\"\"This function is decoding a few examples and printing correct and incorrect cases.\"\"\"\n",
        "    # This block is decoding sequences back to words via tokenizer index\n",
        "    indexWord = {v:k for k,v in tokenizerObj.word_index.items()}\n",
        "    def decodeSeq(seq):\n",
        "        # This function is converting integer sequence to readable text (partial).\n",
        "        words = []\n",
        "        for id in seq:\n",
        "            if id == 0:\n",
        "                continue\n",
        "            w = indexWord.get(id, \"<OOV>\")\n",
        "            words.append(w)\n",
        "            if len(words) > 30:\n",
        "                break\n",
        "        return \" \".join(words)\n",
        "    # This block is collecting some correct and incorrect indices.\n",
        "    correctIdx = [i for i,(a,b) in enumerate(zip(y_true, y_pred)) if a==b]\n",
        "    incorrectIdx = [i for i,(a,b) in enumerate(zip(y_true, y_pred)) if a!=b]\n",
        "    print(\"Total correct are\", len(correctIdx), \"Total incorrect are\", len(incorrectIdx))\n",
        "    print(\"\\n--- Examples of incorrect predictions ---\")\n",
        "    for idx in incorrectIdx[:numExamples]:\n",
        "        print(f\"\\nLabel={y_true[idx]} Pred={y_pred[idx]} Prob={probs[idx]:.3f}\")\n",
        "        print(\"Left:\", decodeSeq(leftTexts[idx]))\n",
        "        print(\"Right:\", decodeSeq(rightTexts[idx]))\n",
        "    print(\"\\n--- Examples of correct predictions ---\")\n",
        "    for idx in correctIdx[:numExamples]:\n",
        "        print(f\"\\nLabel={y_true[idx]} Pred={y_pred[idx]} Prob={probs[idx]:.3f}\")\n",
        "        print(\"Left:\", decodeSeq(leftTexts[idx]))\n",
        "        print(\"Right:\", decodeSeq(rightTexts[idx]))\n"
      ],
      "metadata": {
        "id": "CZGC952STEZN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: train and evaluate Siamese BiLSTM\n",
        "# This cell is building and training the Siamese BiLSTM model.\n",
        "\n",
        "vocabSizeActual = min(maxVocabSize, len(tokenizer.word_index) + 1)\n",
        "builder = ModelBuilder(vocabSize=vocabSizeActual, embeddingDim=embeddingDim, maxLen=maxSeqLen)\n",
        "siameseModel = builder.buildSiameseBiLstm(lstmUnits=64, dropout=0.2)\n",
        "siameseModel.summary()\n",
        "\n",
        "# This block is fitting the siamese model.\n",
        "historySiamese, bestPathSiamese = fitModel(siameseModel, X_train, y_train, modelName=\"siameseBiLstm\", epochs=numEpochs)\n",
        "\n",
        "# This block is evaluating on test set.\n",
        "metricsSiamese, probsSiamese, predsSiamese = evaluateModel(siameseModel, X_test, y_test)\n",
        "print(\"Siamese BiLSTM metrics are:\", metricsSiamese)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "imXdkTZGPlCK",
        "outputId": "8a8ce857-9682-40f7-8794-f33373049316"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"siameseBiLstm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"siameseBiLstm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ leftInput           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ rightInput          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ siameseEncoder      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │  \u001b[38;5;34m3,947,072\u001b[0m │ leftInput[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ rightInput[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ siameseEncoder[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ siameseEncoder[\u001b[38;5;34m1\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ siameseEncoder[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ siameseEncoder[\u001b[38;5;34m1\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ leftInput           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ rightInput          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ siameseEncoder      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,947,072</span> │ leftInput[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ rightInput[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ siameseEncoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ siameseEncoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ siameseEncoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ siameseEncoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,963,713\u001b[0m (15.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,963,713</span> (15.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,963,713\u001b[0m (15.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,963,713</span> (15.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.01566, saving model to /content/siameseBiLstm_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1415/1415 - 73s - 52ms/step - accuracy: 0.9691 - loss: 0.0754 - val_accuracy: 0.9956 - val_loss: 0.0157\n",
            "Epoch 2/12\n",
            "\n",
            "Epoch 2: val_loss improved from 0.01566 to 0.01277, saving model to /content/siameseBiLstm_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1415/1415 - 69s - 48ms/step - accuracy: 0.9956 - loss: 0.0172 - val_accuracy: 0.9971 - val_loss: 0.0128\n",
            "Epoch 3/12\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.01277\n",
            "1415/1415 - 67s - 47ms/step - accuracy: 0.9968 - loss: 0.0127 - val_accuracy: 0.9973 - val_loss: 0.0132\n",
            "Epoch 4/12\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.01277\n",
            "1415/1415 - 69s - 49ms/step - accuracy: 0.9973 - loss: 0.0101 - val_accuracy: 0.9964 - val_loss: 0.0137\n",
            "Epoch 5/12\n",
            "\n",
            "Epoch 5: val_loss improved from 0.01277 to 0.00822, saving model to /content/siameseBiLstm_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1415/1415 - 67s - 48ms/step - accuracy: 0.9979 - loss: 0.0078 - val_accuracy: 0.9978 - val_loss: 0.0082\n",
            "Epoch 6/12\n",
            "\n",
            "Epoch 6: val_loss improved from 0.00822 to 0.00661, saving model to /content/siameseBiLstm_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1415/1415 - 67s - 47ms/step - accuracy: 0.9984 - loss: 0.0057 - val_accuracy: 0.9983 - val_loss: 0.0066\n",
            "Epoch 7/12\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.00661\n",
            "1415/1415 - 67s - 47ms/step - accuracy: 0.9986 - loss: 0.0050 - val_accuracy: 0.9986 - val_loss: 0.0083\n",
            "Epoch 8/12\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.00661\n",
            "1415/1415 - 66s - 47ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.9984 - val_loss: 0.0087\n",
            "Epoch 9/12\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.00661\n",
            "1415/1415 - 82s - 58ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.9986 - val_loss: 0.0077\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "Siamese BiLSTM metrics are: {'accuracy': 0.9982531274653443, 'precision': 0.9966857656443097, 'recall': 0.9998309478192269, 'f1': 0.9982558793743671, 'roc_auc': np.float64(0.9998996207030221)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: train and evaluate Attention-based Encoder\n",
        "# This cell is building and training the attention encoder model.\n",
        "\n",
        "attentionModel = builder.buildAttentionEncoder(lstmUnits=64, dropout=0.2)\n",
        "attentionModel.summary()\n",
        "\n",
        "historyAttn, bestPathAttn = fitModel(attentionModel, X_train, y_train, modelName=\"attentionEncoder\", epochs=numEpochs)\n",
        "metricsAttn, probsAttn, predsAttn = evaluateModel(attentionModel, X_test, y_test)\n",
        "print(\"Attention Encoder metrics are:\", metricsAttn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oxvY38cFV01N",
        "outputId": "71e57c61-a959-4614-e196-04d36b9247c3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"attentionEncoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"attentionEncoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ left_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ right_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ sharedEmbedding     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m3,840,000\u001b[0m │ left_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ right_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ left_bilstm         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m98,816\u001b[0m │ sharedEmbedding[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ right_bilstm        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m98,816\u001b[0m │ sharedEmbedding[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │        \u001b[38;5;34m129\u001b[0m │ left_bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │        \u001b[38;5;34m129\u001b[0m │ right_bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_1 (\u001b[38;5;33mSoftmax\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ left_bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ softmax[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ right_bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ softmax_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_4 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ lambda_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m49,408\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ left_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ right_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ sharedEmbedding     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ left_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ right_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ left_bilstm         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ sharedEmbedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ right_bilstm        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ sharedEmbedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ left_bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ right_bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ left_bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ softmax[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ right_bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ softmax_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ lambda_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,120,323\u001b[0m (15.72 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,120,323</span> (15.72 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,120,323\u001b[0m (15.72 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,120,323</span> (15.72 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.02501, saving model to /content/attentionEncoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1415/1415 - 82s - 58ms/step - accuracy: 0.9395 - loss: 0.1300 - val_accuracy: 0.9953 - val_loss: 0.0250\n",
            "Epoch 2/12\n",
            "\n",
            "Epoch 2: val_loss improved from 0.02501 to 0.01834, saving model to /content/attentionEncoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1415/1415 - 75s - 53ms/step - accuracy: 0.9947 - loss: 0.0234 - val_accuracy: 0.9964 - val_loss: 0.0183\n",
            "Epoch 3/12\n",
            "\n",
            "Epoch 3: val_loss improved from 0.01834 to 0.01822, saving model to /content/attentionEncoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1415/1415 - 75s - 53ms/step - accuracy: 0.9961 - loss: 0.0183 - val_accuracy: 0.9960 - val_loss: 0.0182\n",
            "Epoch 4/12\n",
            "\n",
            "Epoch 4: val_loss improved from 0.01822 to 0.01496, saving model to /content/attentionEncoder_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1415/1415 - 82s - 58ms/step - accuracy: 0.9973 - loss: 0.0139 - val_accuracy: 0.9973 - val_loss: 0.0150\n",
            "Epoch 5/12\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.01496\n",
            "1415/1415 - 75s - 53ms/step - accuracy: 0.9975 - loss: 0.0125 - val_accuracy: 0.9951 - val_loss: 0.0184\n",
            "Epoch 6/12\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.01496\n",
            "1415/1415 - 74s - 53ms/step - accuracy: 0.9981 - loss: 0.0098 - val_accuracy: 0.9969 - val_loss: 0.0176\n",
            "Epoch 7/12\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.01496\n",
            "1415/1415 - 74s - 53ms/step - accuracy: 0.9980 - loss: 0.0096 - val_accuracy: 0.9959 - val_loss: 0.0225\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "Attention Encoder metrics are: {'accuracy': 0.9970979375633946, 'precision': 0.9950614512598911, 'recall': 0.9991547390961344, 'f1': 0.9971038942780824, 'roc_auc': np.float64(0.9981596848393327)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: comparative results and qualitative examples\n",
        "# This cell is printing comparative metrics side-by-side and showing qualitative examples.\n",
        "\n",
        "print(\"=== Comparative Metrics ===\")\n",
        "print(\"Model\\t\\tAccuracy\\tPrecision\\tRecall\\t\\tF1\\t\\tROC-AUC\")\n",
        "print(\"SiameseBiLSTM\\t{acc:.4f}\\t{prec:.4f}\\t\\t{rec:.4f}\\t\\t{f1:.4f}\\t{roc:.4f}\".format(\n",
        "    acc=metricsSiamese['accuracy'], prec=metricsSiamese['precision'], rec=metricsSiamese['recall'],\n",
        "    f1=metricsSiamese['f1'], roc=metricsSiamese['roc_auc']))\n",
        "print(\"AttentionEnc\\t{acc:.4f}\\t{prec:.4f}\\t\\t{rec:.4f}\\t\\t{f1:.4f}\\t{roc:.4f}\".format(\n",
        "    acc=metricsAttn['accuracy'], prec=metricsAttn['precision'], rec=metricsAttn['recall'],\n",
        "    f1=metricsAttn['f1'], roc=metricsAttn['roc_auc']))\n",
        "\n",
        "# This block is showing qualitative examples for the better model (based on f1).\n",
        "betterModelName = \"siamese\" if metricsSiamese['f1'] >= metricsAttn['f1'] else \"attention\"\n",
        "print(\"\\nBetter model by F1 is\", betterModelName)\n",
        "\n",
        "# This block is preparing sequences for decoding (we need original sequences).\n",
        "leftPadAll = np.vstack([X_test[:,0]])\n",
        "# But earlier we had leftPad/rightPad from the whole dataset; we will reconstruct arrays for the test set.\n",
        "leftTestSeqs = X_test[:,0]\n",
        "rightTestSeqs = X_test[:,1]\n",
        "\n",
        "if betterModelName == \"siamese\":\n",
        "    showQualitativeExamples(leftTestSeqs, rightTestSeqs, y_test, predsSiamese, probsSiamese, tokenizer, maxLen=maxSeqLen, numExamples=6)\n",
        "else:\n",
        "    showQualitativeExamples(leftTestSeqs, rightTestSeqs, y_test, predsAttn, probsAttn, tokenizer, maxLen=maxSeqLen, numExamples=6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kEjNJXLYM-1",
        "outputId": "9219f320-54d7-4749-878a-850263a40b61"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Comparative Metrics ===\n",
            "Model\t\tAccuracy\tPrecision\tRecall\t\tF1\t\tROC-AUC\n",
            "SiameseBiLSTM\t0.9983\t0.9967\t\t0.9998\t\t0.9983\t0.9999\n",
            "AttentionEnc\t0.9971\t0.9951\t\t0.9992\t\t0.9971\t0.9982\n",
            "\n",
            "Better model by F1 is siamese\n",
            "Total correct are 35430 Total incorrect are 62\n",
            "\n",
            "--- Examples of incorrect predictions ---\n",
            "\n",
            "Label=0 Pred=1 Prob=0.767\n",
            "Left: documents servicing system data tape\n",
            "Right: support during the first sixty 60 days following the effective date the “initial period” oanda will provide licensee with up to two free hours of telephone support during <OOV> regular customer\n",
            "\n",
            "Label=0 Pred=1 Prob=0.826\n",
            "Left: investment company act none of the borrower or any subsidiary is required to register as an “investment company ” as defined in the investment company act\n",
            "Right: investment company the company is not required to be registered as and is not an affiliate of and immediately following the closing will not be required to register as an “investment\n",
            "\n",
            "Label=0 Pred=1 Prob=0.979\n",
            "Left: reimbursement if the issuing bank shall make any lc disbursement the issuing bank shall promptly notify the company by telephone facsimile or other telecommunication of the date and amount of such\n",
            "Right: term of employment employee's employment under this agreement shall commence effective the 1st day of january 1996 and shall continue for a period of two years unless terminated or renewed under\n",
            "\n",
            "Label=0 Pred=1 Prob=0.999\n",
            "Left: maintenance of insurance maintain insurance on its properties and with respect to the conduct of its business of such kinds and in such substantially similar amounts as presently carried by it\n",
            "Right: maintenance of properties maintain its properties in good working order and condition\n",
            "\n",
            "Label=0 Pred=1 Prob=0.635\n",
            "Left: reinstatement if this agreement is terminated with respect to any portion or portions of the operated facilities pursuant to section 12 1 12 2 or 12 3 and thereafter such portion\n",
            "Right: permits the company and each of the subsidiaries possess all necessary licenses authorizations consents and approvals and have made all necessary filings required under any federal state local or foreign law\n",
            "\n",
            "Label=0 Pred=1 Prob=1.000\n",
            "Left: maintenance of properties except if the failure to do so would not reasonably be expected to have individually or in the aggregate a material adverse effect maintain preserve and protect all\n",
            "Right: maintenance of insurance a seller shall i maintain or cause to be maintained in full force and effect all policies of insurance of any kind with respect to seller’s property and\n",
            "\n",
            "--- Examples of correct predictions ---\n",
            "\n",
            "Label=0 Pred=0 Prob=0.000\n",
            "Left: renewal option lessee may at the end of the term of the original lease exercise the option to renew said lease at the same rate of rent per month and all\n",
            "Right: duration subject to possible dissolution or termination in accordance with sections 10 2 and 10 3 respectively the trust created hereby shall have perpetual existence\n",
            "\n",
            "Label=1 Pred=1 Prob=1.000\n",
            "Left: security the receiving party will implement and maintain at all times during the term appropriate administrative technical and operational safeguards consistent with good industry practices and applicable law but not less\n",
            "Right: security the walker warrants to keep safe and confidential all keys remote control entry devices access codes and personal information of the owner and to return same to the owner at\n",
            "\n",
            "Label=1 Pred=1 Prob=1.000\n",
            "Left: complete agreement this agreement constitutes the entire agreement between company and you with respect to the services provided by and supersedes all prior or contemporaneous understandings regarding such subject matter the\n",
            "Right: complete agreement this agreement and the plan constitute the complete and exclusive agreement between the company and the option holder with respect to the subject matter herein and replace and supersede\n",
            "\n",
            "Label=1 Pred=1 Prob=1.000\n",
            "Left: restrictions a the owner trustee shall not take any action x that is inconsistent with the purposes of the trust set forth in section 2 03 or y that to the\n",
            "Right: restrictions the performance share units may not be sold assigned transferred pledged hypothecated or otherwise disposed of except by will or the laws of descent and distribution prior to the lapse\n",
            "\n",
            "Label=0 Pred=0 Prob=0.000\n",
            "Left: notice of defaults in the event that the company or any of its subsidiaries receives written notice from any holder of indebtedness that the full amount of such indebtedness has been\n",
            "Right: specific performance it is expressly agreed that the remedy at law for breach of any of the obligations set forth in this article 14 is inadequate in view of the complexities\n",
            "\n",
            "Label=1 Pred=1 Prob=1.000\n",
            "Left: additional documents the parties agree to execute and to deliver to each other any and all other additional documents and to take any additional steps reasonably necessary to complete to document\n",
            "Right: additional documents the owner agrees to execute or provide any additional documents reasonably needed by the easement holder to carry out in perpetuity the provisions and the intent of this easement\n"
          ]
        }
      ]
    }
  ]
}